{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "outside-pencil",
   "metadata": {},
   "source": [
    "# Chapter 1 Your First Web Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-circumstances",
   "metadata": {},
   "source": [
    "## 1 Connecting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-decimal",
   "metadata": {},
   "source": [
    "A web browser is a useful application for creating packets of information, telling operating system to send them off, and interpreting the data as pretty pictures, sounds, videos, and text. A web browser can tell the processor to send data to the application that handles wireless interface, but we can do the same thing in Python with just three lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "arranged-shepherd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "### get request\n",
    "from urllib.request import urlopen\n",
    "\n",
    "html = urlopen(\"http://pythonscraping.com/pages/page1.html\")\n",
    "print(html.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-action",
   "metadata": {},
   "source": [
    "`urllib` is a standard Python library and contains functions for requesting data across the web, handling cookies, and even changing metadata such as headers and your user agent.\n",
    "\n",
    "`urlopen` is used to open a remote object across a network and read it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-probe",
   "metadata": {},
   "source": [
    "## 2 An Introduction to BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-stephen",
   "metadata": {},
   "source": [
    "The `BeautifulSoup` library tries to make sense of the nonsensical; it helps format and organize the messy web by fixing bad HTML and presenting us with easily traversable Python objects representing XML structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-syntax",
   "metadata": {},
   "source": [
    "### 2.1 Running BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-anniversary",
   "metadata": {},
   "source": [
    "The most commonly used object in the `BeautifulSoup` library is the `BeautifulSoup` object. Look at the example above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loving-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen(\"http://pythonscraping.com/pages/page1.html\")\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "print(bs.h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-sister",
   "metadata": {},
   "source": [
    "When we create a `BeautifulSoup` object, two arguments are passed in. The first one is the HTML text the object is based on, and the second specifies the parser that you want `BeautifulSoup` to use in order to create that object. In the majority of cases, it makes no difference which parser you choose. `html.parser` is a parser that is included with Python and requires no extra installation in order to use. Except where required, we will use this parser by default.\n",
    "\n",
    "Another popular parser is `lxml`. `lxml` has some advantages over `html.parser` in that it is generally better at parsing messy or malformed HTML code. It is forgiving and fixes problems like unclosed tags, tags that are improperly nested, and missing head or body tags. It is also somewhat faster.\n",
    "\n",
    "Another popular parser is `html5lib`. Like `lxml`, `html5lib` is an extremely forgiving parser that takes even more initiative correcting broken HTML. But it is slower than both `lxml` and `html.parser`.\n",
    "\n",
    "The last line of code only returns the first instance of h1 tag found on the web page. By convention, only one h1 tag should be used on a single page, but conventions are often broken on the web, so you should be aware that this will retrieve the first instance of the tag only, and not necessarily the one that you are looking for.\n",
    "\n",
    "`BeautifulSoup` can use the file object retrieved by `urlopen` without needing to call `.read()` first. Another useful method of `BeautifulSoup` object is `.prettify()` which restructure the HTML code and make it easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amber-north",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   A Useful Page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   An Interesting Title\n",
      "  </h1>\n",
      "  <div>\n",
      "   Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bs.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-third",
   "metadata": {},
   "source": [
    "We can find that the h1 tag we extract is nested two layers deep into the `BeautifulSoup` object structure (html $\\rightarrow$ body $\\rightarrow$ h1). However, when you actually fetch it from the object, you can call h1 tag directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "connected-there",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>An Interesting Title</h1>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.h1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-maria",
   "metadata": {},
   "source": [
    "In fact, any of the following function calls would produce the same output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "above-richardson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>An Interesting Title</h1>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.html.body.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dominican-berlin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>An Interesting Title</h1>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.body.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cutting-biology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>An Interesting Title</h1>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.html.h1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-spider",
   "metadata": {},
   "source": [
    "Virtually any information can be extracted from any HTML file, as long as it has an identifying tag surrounding it or near it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-consolidation",
   "metadata": {},
   "source": [
    "## 3 Connecting Reliably and Handling Exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-letter",
   "metadata": {},
   "source": [
    "Two main things can go wrong in retrieving HTML file using `urlopen`: the page is not found on the server, or the server is not found.\n",
    "\n",
    "In the first situation, an `HTTPError` will be returned. This `HTTPError` may be \"404 Page Not Found\", \"500 Internal Server Error\", and so forth. In all of these cases, the `urlopen` function will throw the generic exception `HTTPError`. We can handle this exception in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sticky-youth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The HTML file is opened.\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "try:\n",
    "    html = urlopen(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"The HTML file is opened.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-reduction",
   "metadata": {},
   "source": [
    "If an `HTTPError` is returned, the program now prints the error, and does not execute the rest of the program under the `else` statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-poverty",
   "metadata": {},
   "source": [
    "If the server is not found at all, `urlopen` will throw an `URLError`. This indicates that no server could be reached at all, and because the remote server is responsible for returning HTTP status code, an `HTTPError` cannot be thrown, and the more serious `URLError` must be caught. We can add a check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "linear-marking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The HTML file is opened.\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "except URLError as e:\n",
    "    print(\"The server could not be found!\")\n",
    "else:\n",
    "    print(\"The HTML file is opened.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-alias",
   "metadata": {},
   "source": [
    "If page is retrieved successfully from the server, there is still the issue of the content on the page not quite being what you expected. Every time you access a tag in a BeautifulSoup object, it's smart to add a check to make sure the tag actually exists. If you attempt to access a tag that does not exits, `BeautifulSoup` will return a `None` object. The problem is, attempting to access a tag on a `None` object itself will result in an `AttributeError` being thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "relevant-region",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### access a non existing object\n",
    "print(bs.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "nervous-treasure",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-cdfae7b21263>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### access a tag on a None object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "### access a tag on a None object\n",
    "print(bs.h5.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-punishment",
   "metadata": {},
   "source": [
    "The easiest way to guard against these two situations is to explicitly check for both situations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "apparent-latvia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'text'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    badContent = bs.h5.text\n",
    "except AttributeError as e:\n",
    "    print(e)\n",
    "else:\n",
    "    if badContent == None:\n",
    "        print(\"Tag was not found.\")\n",
    "    else:\n",
    "        print(badContent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-renewal",
   "metadata": {},
   "source": [
    "We can reorganize the test code to make it less difficult to write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "excellent-satin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        bs = BeautifulSoup(html, \"html.parser\")\n",
    "        title = bs.body.h1\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return title\n",
    "\n",
    "title = getTitle(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "if title == None:\n",
    "    print(\"Title could not be found.\")\n",
    "else:\n",
    "    print(title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
